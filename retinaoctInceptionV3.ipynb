{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 此版本现在多了confusion matrix, 取消l2, 进行finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, utils\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils import data\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def splitData(datadir,val_size = 0.2):\n",
    "    \n",
    "#     train_trainsforms = transforms.Compose([transforms.RandomResizedCrop(299),\n",
    "#                 transforms.RandomHorizontalFlip(),\n",
    "#                 transforms.RandomRotation(30),\n",
    "#                 transforms.ToTensor(),\n",
    "#                 #transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])\n",
    "#                 transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])\n",
    "#     val_trainsforms = transforms.Compose([transforms.RandomResizedCrop(299),\n",
    "#                 transforms.ToTensor(),\n",
    "#                 transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "# ])\n",
    "\n",
    "#     train_data = datasets.ImageFolder(datadir,transform=train_trainsforms)\n",
    "#     val_data = datasets.ImageFolder(datadir,transform=val_trainsforms)\n",
    "\n",
    "#     num = len(train_data)                              \n",
    "#     idx = list(range(num))                         \n",
    "#     split = int(np.floor(val_size * num))         \n",
    "#     np.random.shuffle(idx)                              \n",
    "\n",
    "#     val_idx, train_idx = idx[:split], idx[split:]\n",
    "#     train_sampler = SubsetRandomSampler(train_idx)            \n",
    "#     val_sampler  = SubsetRandomSampler(val_idx)\n",
    "#     train_loader = data.DataLoader(train_data,sampler=train_sampler,batch_size=64)\n",
    "#     val_loader = data.DataLoader(val_data,sampler=val_sampler,batch_size=64)\n",
    "    \n",
    "#     return train_loader,val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weights_for_balanced_classes(images, nclasses):                        \n",
    "    count = [0] * nclasses                                                      \n",
    "    for item in images:                                                         \n",
    "        count[item[1]] += 1                                                     \n",
    "    weight_per_class = [0.] * nclasses                                      \n",
    "    N = float(sum(count))                                                   \n",
    "    for i in range(nclasses):                                                   \n",
    "        weight_per_class[i] = 1/float(count[i])                                 \n",
    "    weight = [0] * len(images)                                              \n",
    "    for idx, val in enumerate(images):                                          \n",
    "        weight[idx] = weight_per_class[val[1]]  \n",
    "    print(N)\n",
    "    print(weight_per_class)\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82484.0\n",
      "[2.7059937762143145e-05, 9.010632546404758e-05, 0.00011953143676786995, 3.836562440053712e-05]\n"
     ]
    }
   ],
   "source": [
    "#train_data_dir = 'OCT2017/test/'\n",
    "#train_loader, val_loader = splitData(train_data_dir,val_size = 0.2)\n",
    "batch_size = 128\n",
    "#train_size = 1600\n",
    "train_data = datasets.ImageFolder(root='OCT2017/train/', transform=transforms.Compose([\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "]))\n",
    "\n",
    "val_data = datasets.ImageFolder(root='OCT2017/val/', transform=transforms.Compose([\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "]))\n",
    "\n",
    "test_data = datasets.ImageFolder(root='OCT2017/test/', transform=transforms.Compose([\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "]))\n",
    "\n",
    "weights = make_weights_for_balanced_classes(train_data.imgs, len(train_data.classes))\n",
    "weights = torch.DoubleTensor(weights)\n",
    "weight_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n",
    "#weight_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, train_size)\n",
    "\n",
    "train_loader = data.DataLoader(train_data,\n",
    "                               batch_size=batch_size,\n",
    "                               sampler = weight_sampler\n",
    "                                            )\n",
    "       \n",
    "\n",
    "val_loader = data.DataLoader(val_data,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=True,\n",
    "                                        )\n",
    "\n",
    "\n",
    "test_loader = data.DataLoader(test_data,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            )\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.232011906372615, 7.4323301495765, 9.859431030360986, 3.164550163053904]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_loader.dataset))\n",
    "82484.0\n",
    "[2.232011906372615, 7.4323301495765, 9.859431030360986, 3.164550163053904]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "inception = models.inception_v3(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception3(\n",
      "  (Conv2d_1a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2b_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_3b_1x1): BasicConv2d(\n",
      "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_4a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Mixed_5b): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5c): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5d): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6a): InceptionB(\n",
      "    (branch3x3): BasicConv2d(\n",
      "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6b): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6c): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6d): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6e): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (AuxLogits): InceptionAux(\n",
      "    (conv0): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1): BasicConv2d(\n",
      "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
      "  )\n",
      "  (Mixed_7a): InceptionD(\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7b): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7c): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(inception)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "#     else:\n",
    "#         for parma in model.parameters():\n",
    "#             parma.requires_grad = False\n",
    "#         for parma in model.Mixed_7c.parameters():\n",
    "#             parma.requires_grad=True\n",
    "#         for parma in model.Mixed_7b.parameters():\n",
    "#             parma.requires_grad=True\n",
    "#         for parma in model.Mixed_7a.parameters():\n",
    "#             parma.requires_grad=True\n",
    "#     else: \n",
    "#         for param in model.parameters():\n",
    "#             param.requires_grad = False\n",
    "#         ct = []\n",
    "#         for name, child in model.named_children():\n",
    "#             if \"Conv2d_4a_3x3\" in ct:\n",
    "#                 for params in child.parameters():\n",
    "#                     params.requires_grad = True\n",
    "#             ct.append(name)       \n",
    "    else:     \n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extract = False\n",
    "para = set_parameter_requires_grad(inception, feature_extract)\n",
    "\n",
    "num_ftrs = inception.fc.in_features\n",
    "#inception.fc=nn.Linear(num_ftrs, out_features=4, bias=True)\n",
    "fc1 = nn.Linear(num_ftrs, out_features=1000, bias=True)\n",
    "inception.fc = nn.Sequential(nn.Linear(num_ftrs, out_features=1000, bias=True),\n",
    "                              nn.Linear(1000, out_features=4, bias=True)\n",
    "                                 )\n",
    "num_ftrs= inception.AuxLogits.fc.in_features\n",
    "inception.AuxLogits.fc=nn.Linear(num_ftrs, out_features=4, bias=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "fine tune:\n",
      "\t Conv2d_1a_3x3.conv.weight\n",
      "\t Conv2d_1a_3x3.bn.weight\n",
      "\t Conv2d_1a_3x3.bn.bias\n",
      "\t Conv2d_2a_3x3.conv.weight\n",
      "\t Conv2d_2a_3x3.bn.weight\n",
      "\t Conv2d_2a_3x3.bn.bias\n",
      "\t Conv2d_2b_3x3.conv.weight\n",
      "\t Conv2d_2b_3x3.bn.weight\n",
      "\t Conv2d_2b_3x3.bn.bias\n",
      "\t Conv2d_3b_1x1.conv.weight\n",
      "\t Conv2d_3b_1x1.bn.weight\n",
      "\t Conv2d_3b_1x1.bn.bias\n",
      "\t Conv2d_4a_3x3.conv.weight\n",
      "\t Conv2d_4a_3x3.bn.weight\n",
      "\t Conv2d_4a_3x3.bn.bias\n",
      "\t Mixed_5b.branch1x1.conv.weight\n",
      "\t Mixed_5b.branch1x1.bn.weight\n",
      "\t Mixed_5b.branch1x1.bn.bias\n",
      "\t Mixed_5b.branch5x5_1.conv.weight\n",
      "\t Mixed_5b.branch5x5_1.bn.weight\n",
      "\t Mixed_5b.branch5x5_1.bn.bias\n",
      "\t Mixed_5b.branch5x5_2.conv.weight\n",
      "\t Mixed_5b.branch5x5_2.bn.weight\n",
      "\t Mixed_5b.branch5x5_2.bn.bias\n",
      "\t Mixed_5b.branch3x3dbl_1.conv.weight\n",
      "\t Mixed_5b.branch3x3dbl_1.bn.weight\n",
      "\t Mixed_5b.branch3x3dbl_1.bn.bias\n",
      "\t Mixed_5b.branch3x3dbl_2.conv.weight\n",
      "\t Mixed_5b.branch3x3dbl_2.bn.weight\n",
      "\t Mixed_5b.branch3x3dbl_2.bn.bias\n",
      "\t Mixed_5b.branch3x3dbl_3.conv.weight\n",
      "\t Mixed_5b.branch3x3dbl_3.bn.weight\n",
      "\t Mixed_5b.branch3x3dbl_3.bn.bias\n",
      "\t Mixed_5b.branch_pool.conv.weight\n",
      "\t Mixed_5b.branch_pool.bn.weight\n",
      "\t Mixed_5b.branch_pool.bn.bias\n",
      "\t Mixed_5c.branch1x1.conv.weight\n",
      "\t Mixed_5c.branch1x1.bn.weight\n",
      "\t Mixed_5c.branch1x1.bn.bias\n",
      "\t Mixed_5c.branch5x5_1.conv.weight\n",
      "\t Mixed_5c.branch5x5_1.bn.weight\n",
      "\t Mixed_5c.branch5x5_1.bn.bias\n",
      "\t Mixed_5c.branch5x5_2.conv.weight\n",
      "\t Mixed_5c.branch5x5_2.bn.weight\n",
      "\t Mixed_5c.branch5x5_2.bn.bias\n",
      "\t Mixed_5c.branch3x3dbl_1.conv.weight\n",
      "\t Mixed_5c.branch3x3dbl_1.bn.weight\n",
      "\t Mixed_5c.branch3x3dbl_1.bn.bias\n",
      "\t Mixed_5c.branch3x3dbl_2.conv.weight\n",
      "\t Mixed_5c.branch3x3dbl_2.bn.weight\n",
      "\t Mixed_5c.branch3x3dbl_2.bn.bias\n",
      "\t Mixed_5c.branch3x3dbl_3.conv.weight\n",
      "\t Mixed_5c.branch3x3dbl_3.bn.weight\n",
      "\t Mixed_5c.branch3x3dbl_3.bn.bias\n",
      "\t Mixed_5c.branch_pool.conv.weight\n",
      "\t Mixed_5c.branch_pool.bn.weight\n",
      "\t Mixed_5c.branch_pool.bn.bias\n",
      "\t Mixed_5d.branch1x1.conv.weight\n",
      "\t Mixed_5d.branch1x1.bn.weight\n",
      "\t Mixed_5d.branch1x1.bn.bias\n",
      "\t Mixed_5d.branch5x5_1.conv.weight\n",
      "\t Mixed_5d.branch5x5_1.bn.weight\n",
      "\t Mixed_5d.branch5x5_1.bn.bias\n",
      "\t Mixed_5d.branch5x5_2.conv.weight\n",
      "\t Mixed_5d.branch5x5_2.bn.weight\n",
      "\t Mixed_5d.branch5x5_2.bn.bias\n",
      "\t Mixed_5d.branch3x3dbl_1.conv.weight\n",
      "\t Mixed_5d.branch3x3dbl_1.bn.weight\n",
      "\t Mixed_5d.branch3x3dbl_1.bn.bias\n",
      "\t Mixed_5d.branch3x3dbl_2.conv.weight\n",
      "\t Mixed_5d.branch3x3dbl_2.bn.weight\n",
      "\t Mixed_5d.branch3x3dbl_2.bn.bias\n",
      "\t Mixed_5d.branch3x3dbl_3.conv.weight\n",
      "\t Mixed_5d.branch3x3dbl_3.bn.weight\n",
      "\t Mixed_5d.branch3x3dbl_3.bn.bias\n",
      "\t Mixed_5d.branch_pool.conv.weight\n",
      "\t Mixed_5d.branch_pool.bn.weight\n",
      "\t Mixed_5d.branch_pool.bn.bias\n",
      "\t Mixed_6a.branch3x3.conv.weight\n",
      "\t Mixed_6a.branch3x3.bn.weight\n",
      "\t Mixed_6a.branch3x3.bn.bias\n",
      "\t Mixed_6a.branch3x3dbl_1.conv.weight\n",
      "\t Mixed_6a.branch3x3dbl_1.bn.weight\n",
      "\t Mixed_6a.branch3x3dbl_1.bn.bias\n",
      "\t Mixed_6a.branch3x3dbl_2.conv.weight\n",
      "\t Mixed_6a.branch3x3dbl_2.bn.weight\n",
      "\t Mixed_6a.branch3x3dbl_2.bn.bias\n",
      "\t Mixed_6a.branch3x3dbl_3.conv.weight\n",
      "\t Mixed_6a.branch3x3dbl_3.bn.weight\n",
      "\t Mixed_6a.branch3x3dbl_3.bn.bias\n",
      "\t Mixed_6b.branch1x1.conv.weight\n",
      "\t Mixed_6b.branch1x1.bn.weight\n",
      "\t Mixed_6b.branch1x1.bn.bias\n",
      "\t Mixed_6b.branch7x7_1.conv.weight\n",
      "\t Mixed_6b.branch7x7_1.bn.weight\n",
      "\t Mixed_6b.branch7x7_1.bn.bias\n",
      "\t Mixed_6b.branch7x7_2.conv.weight\n",
      "\t Mixed_6b.branch7x7_2.bn.weight\n",
      "\t Mixed_6b.branch7x7_2.bn.bias\n",
      "\t Mixed_6b.branch7x7_3.conv.weight\n",
      "\t Mixed_6b.branch7x7_3.bn.weight\n",
      "\t Mixed_6b.branch7x7_3.bn.bias\n",
      "\t Mixed_6b.branch7x7dbl_1.conv.weight\n",
      "\t Mixed_6b.branch7x7dbl_1.bn.weight\n",
      "\t Mixed_6b.branch7x7dbl_1.bn.bias\n",
      "\t Mixed_6b.branch7x7dbl_2.conv.weight\n",
      "\t Mixed_6b.branch7x7dbl_2.bn.weight\n",
      "\t Mixed_6b.branch7x7dbl_2.bn.bias\n",
      "\t Mixed_6b.branch7x7dbl_3.conv.weight\n",
      "\t Mixed_6b.branch7x7dbl_3.bn.weight\n",
      "\t Mixed_6b.branch7x7dbl_3.bn.bias\n",
      "\t Mixed_6b.branch7x7dbl_4.conv.weight\n",
      "\t Mixed_6b.branch7x7dbl_4.bn.weight\n",
      "\t Mixed_6b.branch7x7dbl_4.bn.bias\n",
      "\t Mixed_6b.branch7x7dbl_5.conv.weight\n",
      "\t Mixed_6b.branch7x7dbl_5.bn.weight\n",
      "\t Mixed_6b.branch7x7dbl_5.bn.bias\n",
      "\t Mixed_6b.branch_pool.conv.weight\n",
      "\t Mixed_6b.branch_pool.bn.weight\n",
      "\t Mixed_6b.branch_pool.bn.bias\n",
      "\t Mixed_6c.branch1x1.conv.weight\n",
      "\t Mixed_6c.branch1x1.bn.weight\n",
      "\t Mixed_6c.branch1x1.bn.bias\n",
      "\t Mixed_6c.branch7x7_1.conv.weight\n",
      "\t Mixed_6c.branch7x7_1.bn.weight\n",
      "\t Mixed_6c.branch7x7_1.bn.bias\n",
      "\t Mixed_6c.branch7x7_2.conv.weight\n",
      "\t Mixed_6c.branch7x7_2.bn.weight\n",
      "\t Mixed_6c.branch7x7_2.bn.bias\n",
      "\t Mixed_6c.branch7x7_3.conv.weight\n",
      "\t Mixed_6c.branch7x7_3.bn.weight\n",
      "\t Mixed_6c.branch7x7_3.bn.bias\n",
      "\t Mixed_6c.branch7x7dbl_1.conv.weight\n",
      "\t Mixed_6c.branch7x7dbl_1.bn.weight\n",
      "\t Mixed_6c.branch7x7dbl_1.bn.bias\n",
      "\t Mixed_6c.branch7x7dbl_2.conv.weight\n",
      "\t Mixed_6c.branch7x7dbl_2.bn.weight\n",
      "\t Mixed_6c.branch7x7dbl_2.bn.bias\n",
      "\t Mixed_6c.branch7x7dbl_3.conv.weight\n",
      "\t Mixed_6c.branch7x7dbl_3.bn.weight\n",
      "\t Mixed_6c.branch7x7dbl_3.bn.bias\n",
      "\t Mixed_6c.branch7x7dbl_4.conv.weight\n",
      "\t Mixed_6c.branch7x7dbl_4.bn.weight\n",
      "\t Mixed_6c.branch7x7dbl_4.bn.bias\n",
      "\t Mixed_6c.branch7x7dbl_5.conv.weight\n",
      "\t Mixed_6c.branch7x7dbl_5.bn.weight\n",
      "\t Mixed_6c.branch7x7dbl_5.bn.bias\n",
      "\t Mixed_6c.branch_pool.conv.weight\n",
      "\t Mixed_6c.branch_pool.bn.weight\n",
      "\t Mixed_6c.branch_pool.bn.bias\n",
      "\t Mixed_6d.branch1x1.conv.weight\n",
      "\t Mixed_6d.branch1x1.bn.weight\n",
      "\t Mixed_6d.branch1x1.bn.bias\n",
      "\t Mixed_6d.branch7x7_1.conv.weight\n",
      "\t Mixed_6d.branch7x7_1.bn.weight\n",
      "\t Mixed_6d.branch7x7_1.bn.bias\n",
      "\t Mixed_6d.branch7x7_2.conv.weight\n",
      "\t Mixed_6d.branch7x7_2.bn.weight\n",
      "\t Mixed_6d.branch7x7_2.bn.bias\n",
      "\t Mixed_6d.branch7x7_3.conv.weight\n",
      "\t Mixed_6d.branch7x7_3.bn.weight\n",
      "\t Mixed_6d.branch7x7_3.bn.bias\n",
      "\t Mixed_6d.branch7x7dbl_1.conv.weight\n",
      "\t Mixed_6d.branch7x7dbl_1.bn.weight\n",
      "\t Mixed_6d.branch7x7dbl_1.bn.bias\n",
      "\t Mixed_6d.branch7x7dbl_2.conv.weight\n",
      "\t Mixed_6d.branch7x7dbl_2.bn.weight\n",
      "\t Mixed_6d.branch7x7dbl_2.bn.bias\n",
      "\t Mixed_6d.branch7x7dbl_3.conv.weight\n",
      "\t Mixed_6d.branch7x7dbl_3.bn.weight\n",
      "\t Mixed_6d.branch7x7dbl_3.bn.bias\n",
      "\t Mixed_6d.branch7x7dbl_4.conv.weight\n",
      "\t Mixed_6d.branch7x7dbl_4.bn.weight\n",
      "\t Mixed_6d.branch7x7dbl_4.bn.bias\n",
      "\t Mixed_6d.branch7x7dbl_5.conv.weight\n",
      "\t Mixed_6d.branch7x7dbl_5.bn.weight\n",
      "\t Mixed_6d.branch7x7dbl_5.bn.bias\n",
      "\t Mixed_6d.branch_pool.conv.weight\n",
      "\t Mixed_6d.branch_pool.bn.weight\n",
      "\t Mixed_6d.branch_pool.bn.bias\n",
      "\t Mixed_6e.branch1x1.conv.weight\n",
      "\t Mixed_6e.branch1x1.bn.weight\n",
      "\t Mixed_6e.branch1x1.bn.bias\n",
      "\t Mixed_6e.branch7x7_1.conv.weight\n",
      "\t Mixed_6e.branch7x7_1.bn.weight\n",
      "\t Mixed_6e.branch7x7_1.bn.bias\n",
      "\t Mixed_6e.branch7x7_2.conv.weight\n",
      "\t Mixed_6e.branch7x7_2.bn.weight\n",
      "\t Mixed_6e.branch7x7_2.bn.bias\n",
      "\t Mixed_6e.branch7x7_3.conv.weight\n",
      "\t Mixed_6e.branch7x7_3.bn.weight\n",
      "\t Mixed_6e.branch7x7_3.bn.bias\n",
      "\t Mixed_6e.branch7x7dbl_1.conv.weight\n",
      "\t Mixed_6e.branch7x7dbl_1.bn.weight\n",
      "\t Mixed_6e.branch7x7dbl_1.bn.bias\n",
      "\t Mixed_6e.branch7x7dbl_2.conv.weight\n",
      "\t Mixed_6e.branch7x7dbl_2.bn.weight\n",
      "\t Mixed_6e.branch7x7dbl_2.bn.bias\n",
      "\t Mixed_6e.branch7x7dbl_3.conv.weight\n",
      "\t Mixed_6e.branch7x7dbl_3.bn.weight\n",
      "\t Mixed_6e.branch7x7dbl_3.bn.bias\n",
      "\t Mixed_6e.branch7x7dbl_4.conv.weight\n",
      "\t Mixed_6e.branch7x7dbl_4.bn.weight\n",
      "\t Mixed_6e.branch7x7dbl_4.bn.bias\n",
      "\t Mixed_6e.branch7x7dbl_5.conv.weight\n",
      "\t Mixed_6e.branch7x7dbl_5.bn.weight\n",
      "\t Mixed_6e.branch7x7dbl_5.bn.bias\n",
      "\t Mixed_6e.branch_pool.conv.weight\n",
      "\t Mixed_6e.branch_pool.bn.weight\n",
      "\t Mixed_6e.branch_pool.bn.bias\n",
      "\t AuxLogits.conv0.conv.weight\n",
      "\t AuxLogits.conv0.bn.weight\n",
      "\t AuxLogits.conv0.bn.bias\n",
      "\t AuxLogits.conv1.conv.weight\n",
      "\t AuxLogits.conv1.bn.weight\n",
      "\t AuxLogits.conv1.bn.bias\n",
      "\t AuxLogits.fc.weight\n",
      "\t AuxLogits.fc.bias\n",
      "\t Mixed_7a.branch3x3_1.conv.weight\n",
      "\t Mixed_7a.branch3x3_1.bn.weight\n",
      "\t Mixed_7a.branch3x3_1.bn.bias\n",
      "\t Mixed_7a.branch3x3_2.conv.weight\n",
      "\t Mixed_7a.branch3x3_2.bn.weight\n",
      "\t Mixed_7a.branch3x3_2.bn.bias\n",
      "\t Mixed_7a.branch7x7x3_1.conv.weight\n",
      "\t Mixed_7a.branch7x7x3_1.bn.weight\n",
      "\t Mixed_7a.branch7x7x3_1.bn.bias\n",
      "\t Mixed_7a.branch7x7x3_2.conv.weight\n",
      "\t Mixed_7a.branch7x7x3_2.bn.weight\n",
      "\t Mixed_7a.branch7x7x3_2.bn.bias\n",
      "\t Mixed_7a.branch7x7x3_3.conv.weight\n",
      "\t Mixed_7a.branch7x7x3_3.bn.weight\n",
      "\t Mixed_7a.branch7x7x3_3.bn.bias\n",
      "\t Mixed_7a.branch7x7x3_4.conv.weight\n",
      "\t Mixed_7a.branch7x7x3_4.bn.weight\n",
      "\t Mixed_7a.branch7x7x3_4.bn.bias\n",
      "\t Mixed_7b.branch1x1.conv.weight\n",
      "\t Mixed_7b.branch1x1.bn.weight\n",
      "\t Mixed_7b.branch1x1.bn.bias\n",
      "\t Mixed_7b.branch3x3_1.conv.weight\n",
      "\t Mixed_7b.branch3x3_1.bn.weight\n",
      "\t Mixed_7b.branch3x3_1.bn.bias\n",
      "\t Mixed_7b.branch3x3_2a.conv.weight\n",
      "\t Mixed_7b.branch3x3_2a.bn.weight\n",
      "\t Mixed_7b.branch3x3_2a.bn.bias\n",
      "\t Mixed_7b.branch3x3_2b.conv.weight\n",
      "\t Mixed_7b.branch3x3_2b.bn.weight\n",
      "\t Mixed_7b.branch3x3_2b.bn.bias\n",
      "\t Mixed_7b.branch3x3dbl_1.conv.weight\n",
      "\t Mixed_7b.branch3x3dbl_1.bn.weight\n",
      "\t Mixed_7b.branch3x3dbl_1.bn.bias\n",
      "\t Mixed_7b.branch3x3dbl_2.conv.weight\n",
      "\t Mixed_7b.branch3x3dbl_2.bn.weight\n",
      "\t Mixed_7b.branch3x3dbl_2.bn.bias\n",
      "\t Mixed_7b.branch3x3dbl_3a.conv.weight\n",
      "\t Mixed_7b.branch3x3dbl_3a.bn.weight\n",
      "\t Mixed_7b.branch3x3dbl_3a.bn.bias\n",
      "\t Mixed_7b.branch3x3dbl_3b.conv.weight\n",
      "\t Mixed_7b.branch3x3dbl_3b.bn.weight\n",
      "\t Mixed_7b.branch3x3dbl_3b.bn.bias\n",
      "\t Mixed_7b.branch_pool.conv.weight\n",
      "\t Mixed_7b.branch_pool.bn.weight\n",
      "\t Mixed_7b.branch_pool.bn.bias\n",
      "\t Mixed_7c.branch1x1.conv.weight\n",
      "\t Mixed_7c.branch1x1.bn.weight\n",
      "\t Mixed_7c.branch1x1.bn.bias\n",
      "\t Mixed_7c.branch3x3_1.conv.weight\n",
      "\t Mixed_7c.branch3x3_1.bn.weight\n",
      "\t Mixed_7c.branch3x3_1.bn.bias\n",
      "\t Mixed_7c.branch3x3_2a.conv.weight\n",
      "\t Mixed_7c.branch3x3_2a.bn.weight\n",
      "\t Mixed_7c.branch3x3_2a.bn.bias\n",
      "\t Mixed_7c.branch3x3_2b.conv.weight\n",
      "\t Mixed_7c.branch3x3_2b.bn.weight\n",
      "\t Mixed_7c.branch3x3_2b.bn.bias\n",
      "\t Mixed_7c.branch3x3dbl_1.conv.weight\n",
      "\t Mixed_7c.branch3x3dbl_1.bn.weight\n",
      "\t Mixed_7c.branch3x3dbl_1.bn.bias\n",
      "\t Mixed_7c.branch3x3dbl_2.conv.weight\n",
      "\t Mixed_7c.branch3x3dbl_2.bn.weight\n",
      "\t Mixed_7c.branch3x3dbl_2.bn.bias\n",
      "\t Mixed_7c.branch3x3dbl_3a.conv.weight\n",
      "\t Mixed_7c.branch3x3dbl_3a.bn.weight\n",
      "\t Mixed_7c.branch3x3dbl_3a.bn.bias\n",
      "\t Mixed_7c.branch3x3dbl_3b.conv.weight\n",
      "\t Mixed_7c.branch3x3dbl_3b.bn.weight\n",
      "\t Mixed_7c.branch3x3dbl_3b.bn.bias\n",
      "\t Mixed_7c.branch_pool.conv.weight\n",
      "\t Mixed_7c.branch_pool.bn.weight\n",
      "\t Mixed_7c.branch_pool.bn.bias\n",
      "\t fc.0.weight\n",
      "\t fc.0.bias\n",
      "\t fc.1.weight\n",
      "\t fc.1.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = inception.parameters()\n",
    "weight_p, bias_p = [],[]\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    print(\"tune fc layer\")\n",
    "    params_to_update = []\n",
    "    for name,param in inception.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            \n",
    "else:\n",
    "    print(\"fine tune:\")\n",
    "    for name,param in inception.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "           \n",
    "        \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "#optimizer_inception = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "optimizer_inception = optim.Adam(list(filter(lambda p: p.requires_grad, inception.parameters())), lr=5e-4, betas=(0.9, 0.99))\n",
    "#optimizer_inception = optim.Adam(params_to_update, lr=0.001, betas=(0.9, 0.99))\n",
    "#optimizer_inception = optim.Adam([{'params': weight_p, 'weight_decay':1e-3},\n",
    "#                      {'params': bias_p, 'weight_decay':0}], lr=0.001, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294\n"
     ]
    }
   ],
   "source": [
    "print(len(list(filter(lambda p: p.requires_grad, inception.parameters()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_lr_scheduler(optimizer, epoch, init_lr=5e-4, lr_decay_epoch=10):\n",
    "    \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (0.3**(epoch // lr_decay_epoch))\n",
    "    #lr = init_lr\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        #lr = lr * 0.1\n",
    "        print('LR is set to {}'.format(lr))\n",
    " \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    " \n",
    "    return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = 1\n",
    "if use_cuda:\n",
    "    inception = inception.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloaders, valloaders, criterion, optimizer, lr_scheduler, num_epoch = 3):\n",
    "    since =time.time()\n",
    "    val_acc_history = []\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    train_loss, val_loss = [], []\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        \n",
    "        optimizer = lr_scheduler(optimizer, epoch)\n",
    "        steps = 0\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epoch))\n",
    "        print('-'*10)\n",
    "                \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0 \n",
    "        for inputs, labels in trainloaders:\n",
    "            #print(labels.data)\n",
    "            model.train()\n",
    "            steps += 1\n",
    "            #print(steps)\n",
    "            \n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs, aux_outputs = model(inputs)\n",
    "            loss_outputs = criterion(outputs, labels)\n",
    "            loss_aux_outputs = criterion(aux_outputs, labels)\n",
    "            loss = loss_outputs + 0.1*loss_aux_outputs\n",
    "\n",
    "            _,preds = torch.max(outputs,1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            running_loss += loss.item()\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "        val_running_loss = 0.0\n",
    "        val_running_corrects = 0\n",
    "        model.eval()\n",
    "        step = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valloaders:\n",
    "                step += 1\n",
    "                #print(step)\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item()\n",
    "                _,preds = torch.max(outputs,1)\n",
    "                #print(preds)\n",
    "                val_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss.append(running_loss / len(trainloaders))\n",
    "        val_loss.append(val_running_loss / len(valloaders))\n",
    "        \n",
    "        train_acc = running_corrects.double() / len(trainloaders.dataset)\n",
    "        val_acc = val_running_corrects.double() / len(valloaders.dataset)\n",
    "        \n",
    "        print(f\"Train loss: {running_loss / len(trainloaders):.3f}..\"\n",
    "              f\"Train accuracy:{train_acc:.3f}..\"\n",
    "              f\"Val loss: {val_running_loss/len(valloaders):.3f}..\"\n",
    "              f\"Val accuracy: {val_acc:.3f}..\"\n",
    "             )\n",
    "\n",
    "                \n",
    "        # deep copy the model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            val_acc_history.append(val_acc)\n",
    "\n",
    "   # print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    conf_matrix = confusion_matrix(preds.data.cpu().numpy(), labels.data.cpu().numpy())\n",
    "    print(conf_matrix)\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    #return model, val_acc_history  \n",
    "    return model, val_acc_history, train_loss, val_loss, conf_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR is set to 0.0005\n",
      "Epoch 1/30\n",
      "----------\n",
      "Train loss: 14.334..Train accuracy:0.916..Val loss: 0.167..Val accuracy: 0.945..\n",
      "Epoch 2/30\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-a06a4f33d34c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_inception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-9c725ea845a4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trainloaders, valloaders, criterion, optimizer, lr_scheduler, num_epoch)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloaders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;31m#print(labels.data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optimizer_inception\n",
    "_, hist,train_loss,val_loss,cm = train(inception, train_loader, val_loader, criterion, optimizer, exp_lr_scheduler, num_epoch = 30)\n",
    "\n",
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.savefig(\"model_3.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, testloaders, criterion):\n",
    "    test_running_corrects = 0\n",
    "    test_running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloaders:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_running_loss += loss.item()\n",
    "            _,preds = torch.max(outputs,1)\n",
    "        \n",
    "            test_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    test_acc = test_running_corrects.double() / len(testloaders.dataset)\n",
    "    conf_matrix = confusion_matrix(preds.data.cpu().numpy(), labels.data.cpu().numpy())\n",
    "    print(conf_matrix)\n",
    "    print(f\"Loss of the network on the 1000 test images: {test_running_loss/len(testloaders):.3f}..\"\n",
    "          f\"Accuracy of the network on the 1000 test images: {test_acc:.3f}..\"\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(inception, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(inception, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
