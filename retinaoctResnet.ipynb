{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 此版本现在多了confusion matrix, 取消l2, 进行finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, utils\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils import data\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def splitData(datadir,val_size = 0.2):\n",
    "    \n",
    "#     train_trainsforms = transforms.Compose([transforms.RandomResizedCrop(299),\n",
    "#                 transforms.RandomHorizontalFlip(),\n",
    "#                 transforms.RandomRotation(30),\n",
    "#                 transforms.ToTensor(),\n",
    "#                 #transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])\n",
    "#                 transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])\n",
    "#     val_trainsforms = transforms.Compose([transforms.RandomResizedCrop(299),\n",
    "#                 transforms.ToTensor(),\n",
    "#                 transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "# ])\n",
    "\n",
    "#     train_data = datasets.ImageFolder(datadir,transform=train_trainsforms)\n",
    "#     val_data = datasets.ImageFolder(datadir,transform=val_trainsforms)\n",
    "\n",
    "#     num = len(train_data)                              \n",
    "#     idx = list(range(num))                         \n",
    "#     split = int(np.floor(val_size * num))         \n",
    "#     np.random.shuffle(idx)                              \n",
    "\n",
    "#     val_idx, train_idx = idx[:split], idx[split:]\n",
    "#     train_sampler = SubsetRandomSampler(train_idx)            \n",
    "#     val_sampler  = SubsetRandomSampler(val_idx)\n",
    "#     train_loader = data.DataLoader(train_data,sampler=train_sampler,batch_size=64)\n",
    "#     val_loader = data.DataLoader(val_data,sampler=val_sampler,batch_size=64)\n",
    "    \n",
    "#     return train_loader,val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weights_for_balanced_classes(images, nclasses):                        \n",
    "    count = [0] * nclasses                                                      \n",
    "    for item in images:                                                         \n",
    "        count[item[1]] += 1                                                     \n",
    "    weight_per_class = [0.] * nclasses                                      \n",
    "    N = float(sum(count))                                                   \n",
    "    for i in range(nclasses):                                                   \n",
    "        weight_per_class[i] = 1/float(count[i])                                 \n",
    "    weight = [0] * len(images)                                              \n",
    "    for idx, val in enumerate(images):                                          \n",
    "        weight[idx] = weight_per_class[val[1]]  \n",
    "    print(N)\n",
    "    print(weight_per_class)\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600.0\n",
      "[0.0025, 0.0025, 0.0025, 0.0025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruochenwen/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/sampler.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.weights = torch.tensor(weights, dtype=torch.double)\n"
     ]
    }
   ],
   "source": [
    "#train_data_dir = 'OCT2017/test/'\n",
    "#train_loader, val_loader = splitData(train_data_dir,val_size = 0.2)\n",
    "batch_size = 128\n",
    "train_size = 1600\n",
    "train_data = datasets.ImageFolder(root='OCT2017/train_limit/', transform=transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "]))\n",
    "\n",
    "val_data = datasets.ImageFolder(root='OCT2017/val/', transform=transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "]))\n",
    "\n",
    "test_data = datasets.ImageFolder(root='OCT2017/test/', transform=transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "]))\n",
    "\n",
    "weights = make_weights_for_balanced_classes(train_data.imgs, len(train_data.classes))\n",
    "weights = torch.DoubleTensor(weights)\n",
    "#weight_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n",
    "weight_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, train_size)\n",
    "\n",
    "train_loader = data.DataLoader(train_data,\n",
    "                               batch_size=batch_size,\n",
    "                               sampler = weight_sampler\n",
    "                                            )\n",
    "       \n",
    "\n",
    "val_loader = data.DataLoader(val_data,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=True,\n",
    "                                        )\n",
    "\n",
    "\n",
    "test_loader = data.DataLoader(test_data,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            )\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.232011906372615, 7.4323301495765, 9.859431030360986, 3.164550163053904]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(val_loader))\n",
    "82484.0\n",
    "[2.232011906372615, 7.4323301495765, 9.859431030360986, 3.164550163053904]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "resnet = models.resnet50(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "#     else:\n",
    "#         for parma in model.parameters():\n",
    "#             parma.requires_grad = False\n",
    "#         for parma in model.layer4.parameters():\n",
    "#              parma.requires_grad=True\n",
    "#         for parma in model.layer3.parameters():\n",
    "#              parma.requires_grad=True\n",
    "#         for parma in model.layer2.parameters():\n",
    "#              parma.requires_grad=True\n",
    "#         for parma in model.layer1.parameters():\n",
    "#              parma.requires_grad=True\n",
    "    else:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extract = True\n",
    "para = set_parameter_requires_grad(resnet, feature_extract)\n",
    "\n",
    "num_ftrs = resnet.fc.in_features\n",
    "#inception.fc=nn.Linear(num_ftrs, out_features=4, bias=True)\n",
    "#fc1 = nn.Linear(num_ftrs, out_features=1000, bias=True)\n",
    "#resnet.fc = nn.Linear(num_ftrs, out_features=4, bias=True)\n",
    "resnet.fc =nn.Sequential(nn.Linear(num_ftrs, out_features=1000, bias=True),\n",
    "                              nn.Linear(1000, out_features=4, bias=True)\n",
    "                                 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n"
     ]
    }
   ],
   "source": [
    "params_to_update = resnet.parameters()\n",
    "\n",
    "fc_params = list(map(id, resnet.fc.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in fc_params,\n",
    "                     resnet.parameters())\n",
    "\n",
    "\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in resnet.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "else:\n",
    "    conv_para = []\n",
    "    fc_para = []\n",
    "    print(\"fine tune:\")\n",
    "    for name,param in resnet.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\", name)\n",
    "\n",
    "\n",
    "        \n",
    "# Observe that all parameters are being optimized\n",
    "#optimizer_inception = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "optimizer_resnet = optim.Adam(list(filter(lambda p: p.requires_grad,resnet.parameters())), lr=5e-4, betas=(0.9, 0.99))\n",
    "#optimizer_inception = optim.Adam(params_to_update, lr=0.001, betas=(0.9, 0.99))\n",
    "#optimizer_resnet = optim.Adam([{'params': resnet.fc.parameters(), 'lr': 5e-5},\n",
    "#                      {'params': base_params, 'lr': 5e-5}], betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def exp_lr_scheduler(optimizer, epoch, lr_decay_epoch=5):\n",
    "#     \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         param_group['lr'] = param_group['lr'] * (0.1**(epoch // lr_decay_epoch))\n",
    "#         # param_group['lr'] = param_group['lr']\n",
    "#     if epoch % lr_decay_epoch == 0:\n",
    "#         for param_group in optimizer.param_groups:\n",
    "#             print('LR is set to {}'.format(param_group['lr']))\n",
    "            \n",
    "#     return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_lr_scheduler(optimizer, epoch, init_lr=5e-5, lr_decay_epoch=10):\n",
    "    \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (0.3**(epoch // lr_decay_epoch))\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        \n",
    "        print('LR is set to {}'.format(lr))\n",
    " \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    " \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = 1\n",
    "if use_cuda:\n",
    "    resnet = resnet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloaders, valloaders, criterion, optimizer, lr_scheduler, num_epoch):\n",
    "    since =time.time()\n",
    "    val_acc_history = []\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    train_loss, val_loss = [], []\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        \n",
    "        model.train()\n",
    "        optimizer = lr_scheduler(optimizer, epoch)\n",
    "        steps = 0\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epoch))\n",
    "        print('-'*10)\n",
    "                \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0 \n",
    "        for inputs, labels in trainloaders:\n",
    "            #print(\"train labels number:\",len(labels.data))\n",
    "            #model.train()\n",
    "            steps += 1\n",
    "            #print(\"train labels:\",labels.data)\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss_outputs = criterion(outputs, labels)\n",
    "            loss = loss_outputs\n",
    "            _,preds = torch.max(outputs,1)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            running_loss += loss.item() \n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        val_running_loss = 0.0\n",
    "        val_running_corrects = 0\n",
    "        model.eval()\n",
    "        step = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valloaders:\n",
    "                step += 1\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item()\n",
    "                _,preds = torch.max(outputs,1)\n",
    "                val_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss.append(running_loss / len(trainloaders))\n",
    "        val_loss.append(val_running_loss / len(valloaders))\n",
    "        \n",
    "        train_acc = running_corrects.double() / len(trainloaders.dataset)\n",
    "        val_acc = val_running_corrects.double() / len(valloaders.dataset)\n",
    "        \n",
    "        print(f\"Train loss: {running_loss / len(trainloaders):.3f}..\"\n",
    "              f\"Train accuracy:{train_acc:.3f}..\"\n",
    "              f\"Val loss: {val_running_loss/len(valloaders):.3f}..\"\n",
    "              f\"Val accuracy: {val_acc:.3f}..\"\n",
    "             )\n",
    "\n",
    "                \n",
    "        # deep copy the model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            val_acc_history.append(val_acc)\n",
    "\n",
    "\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    conf_matrix = confusion_matrix(preds.data.cpu().numpy(), labels.data.cpu().numpy())\n",
    "    print(conf_matrix)\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, val_acc_history, train_loss, val_loss, conf_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR is set to 5e-05\n",
      "Epoch 1/20\n",
      "----------\n",
      "Train loss: 1.314..Train accuracy:0.421..Val loss: 1.286..Val accuracy: 0.483..\n",
      "Epoch 2/20\n",
      "----------\n",
      "Train loss: 1.160..Train accuracy:0.597..Val loss: 1.201..Val accuracy: 0.524..\n",
      "Epoch 3/20\n",
      "----------\n",
      "Train loss: 1.058..Train accuracy:0.616..Val loss: 1.110..Val accuracy: 0.561..\n",
      "Epoch 4/20\n",
      "----------\n",
      "Train loss: 0.968..Train accuracy:0.662..Val loss: 0.972..Val accuracy: 0.671..\n",
      "Epoch 5/20\n",
      "----------\n",
      "Train loss: 0.929..Train accuracy:0.672..Val loss: 0.933..Val accuracy: 0.664..\n",
      "Epoch 6/20\n",
      "----------\n",
      "Train loss: 0.885..Train accuracy:0.662..Val loss: 0.886..Val accuracy: 0.682..\n",
      "Epoch 7/20\n",
      "----------\n",
      "Train loss: 0.870..Train accuracy:0.684..Val loss: 0.860..Val accuracy: 0.689..\n",
      "Epoch 8/20\n",
      "----------\n",
      "Train loss: 0.840..Train accuracy:0.683..Val loss: 0.853..Val accuracy: 0.681..\n",
      "Epoch 9/20\n",
      "----------\n",
      "Train loss: 0.810..Train accuracy:0.700..Val loss: 0.824..Val accuracy: 0.701..\n",
      "Epoch 10/20\n",
      "----------\n",
      "Train loss: 0.757..Train accuracy:0.723..Val loss: 0.789..Val accuracy: 0.732..\n",
      "LR is set to 1.5e-05\n",
      "Epoch 11/20\n",
      "----------\n",
      "Train loss: 0.745..Train accuracy:0.731..Val loss: 0.782..Val accuracy: 0.718..\n",
      "Epoch 12/20\n",
      "----------\n",
      "Train loss: 0.754..Train accuracy:0.730..Val loss: 0.769..Val accuracy: 0.727..\n",
      "Epoch 13/20\n",
      "----------\n",
      "Train loss: 0.759..Train accuracy:0.723..Val loss: 0.797..Val accuracy: 0.708..\n",
      "Epoch 14/20\n",
      "----------\n",
      "Train loss: 0.752..Train accuracy:0.712..Val loss: 0.770..Val accuracy: 0.719..\n",
      "Epoch 15/20\n",
      "----------\n",
      "Train loss: 0.742..Train accuracy:0.709..Val loss: 0.756..Val accuracy: 0.738..\n",
      "Epoch 16/20\n",
      "----------\n",
      "Train loss: 0.740..Train accuracy:0.711..Val loss: 0.763..Val accuracy: 0.727..\n",
      "Epoch 17/20\n",
      "----------\n",
      "Train loss: 0.741..Train accuracy:0.708..Val loss: 0.747..Val accuracy: 0.731..\n",
      "Epoch 18/20\n",
      "----------\n",
      "Train loss: 0.744..Train accuracy:0.729..Val loss: 0.752..Val accuracy: 0.728..\n",
      "Epoch 19/20\n",
      "----------\n",
      "Train loss: 0.724..Train accuracy:0.739..Val loss: 0.741..Val accuracy: 0.733..\n",
      "Epoch 20/20\n",
      "----------\n",
      "Train loss: 0.721..Train accuracy:0.734..Val loss: 0.750..Val accuracy: 0.722..\n",
      "Training complete in 5m 27s\n",
      "Best val Acc: 0.738000\n",
      "[[16  4  4  0]\n",
      " [ 2 13  3  2]\n",
      " [ 4  3 24  3]\n",
      " [ 0  2  3 21]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optimizer_resnet\n",
    "_, hist,train_loss,val_loss,cm = train(resnet, train_loader, val_loader, criterion, optimizer, exp_lr_scheduler, num_epoch =20)\n",
    "\n",
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.savefig(\"model_3.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  4  4  0]\n",
      " [ 2 13  3  2]\n",
      " [ 4  3 24  3]\n",
      " [ 0  2  3 21]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, testloaders, criterion):\n",
    "    test_running_corrects = 0\n",
    "    test_running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloaders:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_running_loss += loss.item()\n",
    "            _,preds = torch.max(outputs,1)\n",
    "            \n",
    "            test_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    test_acc = test_running_corrects.double() / len(testloaders.dataset)\n",
    "    conf_matrix = confusion_matrix(preds.data.cpu().numpy(), labels.data.cpu().numpy())\n",
    "    print(conf_matrix)\n",
    "    print(f\"Loss of the network on the 1000 test images: {test_running_loss/len(testloaders):.3f}..\"\n",
    "          f\"Accuracy of the network on the 1000 test images: {test_acc:.3f}..\"\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  5  3  0]\n",
      " [ 2 14  0  2]\n",
      " [ 2  2 24  1]\n",
      " [ 0  1  0 27]]\n",
      "Loss of the network on the 1000 test images: 0.580..Accuracy of the network on the 1000 test images: 0.842..\n"
     ]
    }
   ],
   "source": [
    "inference(resnet, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
