{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 记得把loss改成和inceptionv3版本一样的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, utils\n",
    "from torchvision import datasets\n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils import data\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def splitData(datadir,val_size = 0.2):\n",
    "    \n",
    "#     train_trainsforms = transforms.Compose([transforms.RandomResizedCrop(299),\n",
    "#                 transforms.RandomHorizontalFlip(),\n",
    "#                 transforms.RandomRotation(30),\n",
    "#                 transforms.ToTensor(),\n",
    "#                 #transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))])\n",
    "#                 transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])\n",
    "#     val_trainsforms = transforms.Compose([transforms.RandomResizedCrop(299),\n",
    "#                 transforms.ToTensor(),\n",
    "#                 transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "# ])\n",
    "\n",
    "#     train_data = datasets.ImageFolder(datadir,transform=train_trainsforms)\n",
    "#     val_data = datasets.ImageFolder(datadir,transform=val_trainsforms)\n",
    "\n",
    "#     num = len(train_data)                              \n",
    "#     idx = list(range(num))                         \n",
    "#     split = int(np.floor(val_size * num))         \n",
    "#     np.random.shuffle(idx)                              \n",
    "\n",
    "#     val_idx, train_idx = idx[:split], idx[split:]\n",
    "#     train_sampler = SubsetRandomSampler(train_idx)            \n",
    "#     val_sampler  = SubsetRandomSampler(val_idx)\n",
    "#     train_loader = data.DataLoader(train_data,sampler=train_sampler,batch_size=64)\n",
    "#     val_loader = data.DataLoader(val_data,sampler=val_sampler,batch_size=64)\n",
    "    \n",
    "#     return train_loader,val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weights_for_balanced_classes(images, nclasses):                        \n",
    "    count = [0] * nclasses                                                      \n",
    "    for item in images:                                                         \n",
    "        count[item[1]] += 1                                                     \n",
    "    weight_per_class = [0.] * nclasses                                      \n",
    "    N = float(sum(count))                                                   \n",
    "    for i in range(nclasses):                                                   \n",
    "        weight_per_class[i] = 1/float(count[i])                                 \n",
    "    weight = [0] * len(images)                                              \n",
    "    for idx, val in enumerate(images):                                          \n",
    "        weight[idx] = weight_per_class[val[1]]  \n",
    "    print(N)\n",
    "    print(weight_per_class)\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600.0\n",
      "[0.0025, 0.0025, 0.0025, 0.0025]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruochenwen/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/sampler.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.weights = torch.tensor(weights, dtype=torch.double)\n"
     ]
    }
   ],
   "source": [
    "#train_data_dir = 'OCT2017/test/'\n",
    "#train_loader, val_loader = splitData(train_data_dir,val_size = 0.2)\n",
    "batch_size = 128\n",
    "train_size = 1600\n",
    "img_size = 224\n",
    "train_data = datasets.ImageFolder(root='OCT2017/train_limit/', transform=transforms.Compose([\n",
    "    transforms.CenterCrop(img_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "]))\n",
    "\n",
    "val_data = datasets.ImageFolder(root='OCT2017/val/', transform=transforms.Compose([\n",
    "    transforms.CenterCrop(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "]))\n",
    "\n",
    "test_data = datasets.ImageFolder(root='OCT2017/test/', transform=transforms.Compose([\n",
    "    transforms.CenterCrop(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "]))\n",
    "\n",
    "weights = make_weights_for_balanced_classes(train_data.imgs, len(train_data.classes))\n",
    "weights = torch.DoubleTensor(weights)\n",
    "weight_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, train_size)\n",
    "#weight_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, train_size)\n",
    "\n",
    "train_loader = data.DataLoader(train_data,\n",
    "                               batch_size=batch_size,\n",
    "                               sampler = weight_sampler\n",
    "                                            )\n",
    "       \n",
    "\n",
    "val_loader = data.DataLoader(val_data,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=True,\n",
    "                                        )\n",
    "\n",
    "\n",
    "test_loader = data.DataLoader(test_data,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            )\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.232011906372615, 7.4323301495765, 9.859431030360986, 3.164550163053904]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(val_loader.dataset))\n",
    "82484.0\n",
    "[2.232011906372615, 7.4323301495765, 9.859431030360986, 3.164550163053904]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "vgg16 = models.vgg16(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extract = False\n",
    "set_parameter_requires_grad(vgg16, feature_extract)\n",
    "num_ftrs = vgg16.classifier[6].in_features\n",
    "vgg16.classifier[6] = nn.Linear(num_ftrs,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "fine tune:\n",
      "\t features.0.weight\n",
      "\t features.0.bias\n",
      "\t features.2.weight\n",
      "\t features.2.bias\n",
      "\t features.5.weight\n",
      "\t features.5.bias\n",
      "\t features.7.weight\n",
      "\t features.7.bias\n",
      "\t features.10.weight\n",
      "\t features.10.bias\n",
      "\t features.12.weight\n",
      "\t features.12.bias\n",
      "\t features.14.weight\n",
      "\t features.14.bias\n",
      "\t features.17.weight\n",
      "\t features.17.bias\n",
      "\t features.19.weight\n",
      "\t features.19.bias\n",
      "\t features.21.weight\n",
      "\t features.21.bias\n",
      "\t features.24.weight\n",
      "\t features.24.bias\n",
      "\t features.26.weight\n",
      "\t features.26.bias\n",
      "\t features.28.weight\n",
      "\t features.28.bias\n",
      "\t classifier.0.weight\n",
      "\t classifier.0.bias\n",
      "\t classifier.3.weight\n",
      "\t classifier.3.bias\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = vgg16.parameters()\n",
    "print\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in vgg16.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(name)\n",
    "else:\n",
    "    print(\"fine tune:\")\n",
    "    for name,param in vgg16.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "           \n",
    "        \n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "#optimizer_vgg16 = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "optimizer_vgg16 = optim.Adam(list(filter(lambda p: p.requires_grad, vgg16.parameters())), lr=5e-6, betas=(0.9, 0.99))\n",
    "#optimizer_vgg16 = optim.Adam(params_to_update, lr=0.001, betas=(0.9, 0.99))\n",
    "#optimizer_vgg16 = optim.Adam([{'params': weight_p, 'weight_decay':1e-3},\n",
    "#                      {'params': bias_p, 'weight_decay':0}], lr=0.001, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "print(len(list(filter(lambda p: p.requires_grad, vgg16.parameters()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_lr_scheduler(optimizer, epoch, init_lr=5e-5, lr_decay_epoch=5):\n",
    "    \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
    "    #lr = init_lr * (0.1**(epoch // lr_decay_epoch))\n",
    "    lr = init_lr \n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        \n",
    "        print('LR is set to {}'.format(lr))\n",
    " \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    " \n",
    "    return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = 1\n",
    "if use_cuda:\n",
    "    vgg16 = vgg16.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloaders, valloaders, criterion, optimizer, lr_scheduler, num_epoch = 3):\n",
    "    since =time.time()\n",
    "    val_acc_history = []\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    train_loss, val_loss = [], []\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        \n",
    "        optimizer = lr_scheduler(optimizer, epoch)\n",
    "        steps = 0\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epoch))\n",
    "        print('-'*10)\n",
    "                \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0 \n",
    "        for inputs, labels in trainloaders:\n",
    "            \n",
    "            model.train()\n",
    "            steps += 1\n",
    "            #print(steps)\n",
    "            \n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs= model(inputs)\n",
    "            loss_outputs = criterion(outputs, labels)\n",
    "            loss = loss_outputs \n",
    "\n",
    "            _,preds = torch.max(outputs,1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            running_loss += loss.item() \n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            #print(\"loss:\", loss.item())\n",
    "            #if steps % print_every == 0:\n",
    "\n",
    "        val_running_loss = 0.0\n",
    "        val_running_corrects = 0\n",
    "        model.eval()\n",
    "        step = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valloaders:\n",
    "                step += 1\n",
    "                #print(step)\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item()\n",
    "                _,preds = torch.max(outputs,1)\n",
    "                #print(preds)\n",
    "                val_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss.append(running_loss / len(trainloaders))\n",
    "        val_loss.append(val_running_loss / len(valloaders))\n",
    "        \n",
    "        #train_acc = running_corrects.double() / len(trainloaders.dataset)\n",
    "        #val_acc = val_running_corrects.double() / len(valloaders.dataset)\n",
    "       \n",
    "        train_acc = running_corrects.double() / len(trainloaders.dataset)\n",
    "        val_acc = val_running_corrects.double() / len(valloaders.dataset)\n",
    "        \n",
    "        print(f\"Train loss: {running_loss / len(trainloaders):.3f}..\"\n",
    "              f\"Train accuracy:{train_acc:.3f}..\"\n",
    "              f\"Val loss: {val_running_loss/len(valloaders):.3f}..\"\n",
    "              f\"Val accuracy: {val_acc:.3f}..\"\n",
    "             )\n",
    "\n",
    "                \n",
    "        # deep copy the model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            val_acc_history.append(val_acc)\n",
    "\n",
    "   # print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    conf_matrix = confusion_matrix(preds.data.cpu().numpy(), labels.data.cpu().numpy())\n",
    "    print(conf_matrix)\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    #return model, val_acc_history  \n",
    "    return model, val_acc_history, train_loss, val_loss, conf_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR is set to 5e-05\n",
      "Epoch 1/30\n",
      "----------\n",
      "Train loss: 1.085..Train accuracy:0.520..Val loss: 0.718..Val accuracy: 0.693..\n",
      "Epoch 2/30\n",
      "----------\n",
      "Train loss: 0.616..Train accuracy:0.738..Val loss: 0.536..Val accuracy: 0.784..\n",
      "Epoch 3/30\n",
      "----------\n",
      "Train loss: 0.461..Train accuracy:0.829..Val loss: 0.419..Val accuracy: 0.839..\n",
      "Epoch 4/30\n",
      "----------\n",
      "Train loss: 0.383..Train accuracy:0.864..Val loss: 0.393..Val accuracy: 0.854..\n",
      "Epoch 5/30\n",
      "----------\n",
      "Train loss: 0.376..Train accuracy:0.868..Val loss: 0.402..Val accuracy: 0.845..\n",
      "LR is set to 5e-05\n",
      "Epoch 6/30\n",
      "----------\n",
      "Train loss: 0.336..Train accuracy:0.881..Val loss: 0.425..Val accuracy: 0.840..\n",
      "Epoch 7/30\n",
      "----------\n",
      "Train loss: 0.274..Train accuracy:0.904..Val loss: 0.407..Val accuracy: 0.855..\n",
      "Epoch 8/30\n",
      "----------\n",
      "Train loss: 0.285..Train accuracy:0.894..Val loss: 0.441..Val accuracy: 0.852..\n",
      "Epoch 9/30\n",
      "----------\n",
      "Train loss: 0.258..Train accuracy:0.906..Val loss: 0.382..Val accuracy: 0.871..\n",
      "Epoch 10/30\n",
      "----------\n",
      "Train loss: 0.202..Train accuracy:0.931..Val loss: 0.354..Val accuracy: 0.878..\n",
      "LR is set to 5e-05\n",
      "Epoch 11/30\n",
      "----------\n",
      "Train loss: 0.183..Train accuracy:0.933..Val loss: 0.356..Val accuracy: 0.884..\n",
      "Epoch 12/30\n",
      "----------\n",
      "Train loss: 0.178..Train accuracy:0.937..Val loss: 0.378..Val accuracy: 0.886..\n",
      "Epoch 13/30\n",
      "----------\n",
      "Train loss: 0.146..Train accuracy:0.943..Val loss: 0.392..Val accuracy: 0.889..\n",
      "Epoch 14/30\n",
      "----------\n",
      "Train loss: 0.140..Train accuracy:0.946..Val loss: 0.454..Val accuracy: 0.879..\n",
      "Epoch 15/30\n",
      "----------\n",
      "Train loss: 0.113..Train accuracy:0.963..Val loss: 0.485..Val accuracy: 0.889..\n",
      "LR is set to 5e-05\n",
      "Epoch 16/30\n",
      "----------\n",
      "Train loss: 0.118..Train accuracy:0.960..Val loss: 0.475..Val accuracy: 0.884..\n",
      "Epoch 17/30\n",
      "----------\n",
      "Train loss: 0.137..Train accuracy:0.948..Val loss: 0.455..Val accuracy: 0.870..\n",
      "Epoch 18/30\n",
      "----------\n",
      "Train loss: 0.097..Train accuracy:0.963..Val loss: 0.444..Val accuracy: 0.882..\n",
      "Epoch 19/30\n",
      "----------\n",
      "Train loss: 0.075..Train accuracy:0.973..Val loss: 0.496..Val accuracy: 0.882..\n",
      "Epoch 20/30\n",
      "----------\n",
      "Train loss: 0.058..Train accuracy:0.975..Val loss: 0.603..Val accuracy: 0.877..\n",
      "LR is set to 5e-05\n",
      "Epoch 21/30\n",
      "----------\n",
      "Train loss: 0.063..Train accuracy:0.979..Val loss: 0.558..Val accuracy: 0.882..\n",
      "Epoch 22/30\n",
      "----------\n",
      "Train loss: 0.067..Train accuracy:0.978..Val loss: 0.550..Val accuracy: 0.889..\n",
      "Epoch 23/30\n",
      "----------\n",
      "Train loss: 0.073..Train accuracy:0.974..Val loss: 0.602..Val accuracy: 0.883..\n",
      "Epoch 24/30\n",
      "----------\n",
      "Train loss: 0.079..Train accuracy:0.975..Val loss: 0.511..Val accuracy: 0.886..\n",
      "Epoch 25/30\n",
      "----------\n",
      "Train loss: 0.054..Train accuracy:0.983..Val loss: 0.626..Val accuracy: 0.872..\n",
      "LR is set to 5e-05\n",
      "Epoch 26/30\n",
      "----------\n",
      "Train loss: 0.103..Train accuracy:0.971..Val loss: 0.592..Val accuracy: 0.861..\n",
      "Epoch 27/30\n",
      "----------\n",
      "Train loss: 0.058..Train accuracy:0.979..Val loss: 0.540..Val accuracy: 0.886..\n",
      "Epoch 28/30\n",
      "----------\n",
      "Train loss: 0.038..Train accuracy:0.990..Val loss: 0.524..Val accuracy: 0.895..\n",
      "Epoch 29/30\n",
      "----------\n",
      "Train loss: 0.038..Train accuracy:0.988..Val loss: 0.790..Val accuracy: 0.856..\n",
      "Epoch 30/30\n",
      "----------\n",
      "Train loss: 0.050..Train accuracy:0.984..Val loss: 0.687..Val accuracy: 0.878..\n",
      "Training complete in 13m 37s\n",
      "Best val Acc: 0.895000\n",
      "[[23  1  0  1]\n",
      " [ 1 27  2  2]\n",
      " [ 2  0 20  0]\n",
      " [ 0  1  1 23]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optimizer_vgg16\n",
    "_, hist,train_loss,val_loss,cm = train(vgg16, train_loader, val_loader, criterion, optimizer, exp_lr_scheduler, num_epoch =30)\n",
    "\n",
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.plot(val_loss, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.savefig(\"model_3.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  1  0  1]\n",
      " [ 1 27  2  2]\n",
      " [ 2  0 20  0]\n",
      " [ 0  1  1 23]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, testloaders, criterion):\n",
    "    test_running_corrects = 0\n",
    "    test_running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloaders:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_running_loss += loss.item()\n",
    "            _,preds = torch.max(outputs,1)\n",
    "            \n",
    "            test_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    test_acc = test_running_corrects.double() / len(testloaders.dataset)\n",
    "    conf_matrix = confusion_matrix(preds.data.cpu().numpy(), labels.data.cpu().numpy())\n",
    "    print(conf_matrix)\n",
    "    print(f\"Loss of the network on the 1000 test images: {test_running_loss/len(testloaders):.3f}..\"\n",
    "          f\"Accuracy of the network on the 1000 test images: {test_acc:.3f}..\"\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  0  4  0]\n",
      " [ 0 25  0  0]\n",
      " [ 0  0 21  0]\n",
      " [ 0  0  0 27]]\n",
      "Loss of the network on the 1000 test images: 0.129..Accuracy of the network on the 1000 test images: 0.968..\n"
     ]
    }
   ],
   "source": [
    "inference(vgg16, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
